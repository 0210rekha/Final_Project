{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 515 train samples and 172 test samples.\n",
      "üîç Missing labels in train set: 0\n",
      "üîç Missing labels in test set: 0\n",
      "‚úÖ Final Train Dataset: 515 samples\n",
      "‚úÖ Final Test Dataset: 172 samples\n"
     ]
    }
   ],
   "source": [
    "#Data preprocessing\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def load_annotations(annotations_folder):\n",
    "    annotations = {}\n",
    "\n",
    "    for json_file in os.listdir(annotations_folder):\n",
    "        if json_file.endswith(\".json\"):  \n",
    "            img_name = json_file.replace(\".json\", \".jpg\")  \n",
    "\n",
    "            json_path = os.path.join(annotations_folder, json_file)\n",
    "\n",
    "            try:\n",
    "                with open(json_path, \"r\") as file:\n",
    "                    data = json.load(file)\n",
    "\n",
    "                    \n",
    "                    # print(f\"üîç JSON Content [{json_file}]:\", json.dumps(data, indent=4))\n",
    "\n",
    "                    \n",
    "                    if isinstance(data, list) and len(data) > 0:\n",
    "                        annotations[img_name] = data[0].get(\"text\", \"\")\n",
    "                    elif isinstance(data, dict):\n",
    "                        annotations[img_name] = data.get(\"text\", \"\")\n",
    "                    else:\n",
    "                        annotations[img_name] = \"\"  \n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error reading {json_file}: {e}\")\n",
    "\n",
    "    return annotations\n",
    "\n",
    "train_dir = 'D:/Projects/Final_project/Dataset/data/train'\n",
    "test_dir = 'D:/Projects/Final_project/Dataset/data/test'\n",
    "\n",
    "train_annotations = load_annotations(train_dir)\n",
    "test_annotations = load_annotations(test_dir)\n",
    "\n",
    "train_df = pd.DataFrame(list(train_annotations.items()), columns=[\"image_name\", \"text\"])\n",
    "test_df = pd.DataFrame(list(test_annotations.items()), columns=[\"image_name\", \"text\"])\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(train_df)} train samples and {len(test_df)} test samples.\")\n",
    "\n",
    "train_images = set(os.listdir(train_dir))\n",
    "test_images = set(os.listdir(test_dir))\n",
    "\n",
    "missing_train = set(train_df[\"image_name\"]) - train_images\n",
    "missing_test = set(test_df[\"image_name\"]) - test_images\n",
    "\n",
    "if missing_train:\n",
    "    print(f\"‚ö†Ô∏è Missing train images: {missing_train}\")\n",
    "if missing_test:\n",
    "    print(f\"‚ö†Ô∏è Missing test images: {missing_test}\")\n",
    "\n",
    "train_df = train_df[~train_df[\"image_name\"].isin(missing_train)]\n",
    "test_df = test_df[~test_df[\"image_name\"].isin(missing_test)]\n",
    "\n",
    "unique_labels = sorted(set(train_df[\"text\"].tolist() + test_df[\"text\"].tolist()))\n",
    "label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "train_df[\"label\"] = train_df[\"text\"].map(label_to_index)\n",
    "test_df[\"label\"] = test_df[\"text\"].map(label_to_index)\n",
    "\n",
    "print(\"üîç Missing labels in train set:\", train_df[\"label\"].isna().sum())\n",
    "print(\"üîç Missing labels in test set:\", test_df[\"label\"].isna().sum())\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "# Define image transformations (preprocessing)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Custom Dataset for loading images and labels\n",
    "class GNHKDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_folder, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.dataframe.iloc[idx][\"image_name\"]\n",
    "        img_path = os.path.join(self.image_folder, img_name)\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"‚ö†Ô∏è Warning: Image {img_path} not found! Skipping...\")\n",
    "            return None  \n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path)\n",
    "            image = image.convert(\"RGB\") if image.mode != \"RGB\" else image  \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error opening {img_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.dataframe.iloc[idx][\"label\"]\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch = [b for b in batch if b is not None]  \n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = GNHKDataset(train_df, train_dir, transform=train_transforms)\n",
    "test_dataset = GNHKDataset(test_df, test_dir, transform=test_transforms)\n",
    "\n",
    "# DataLoaders for batch processing\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(f\"‚úÖ Final Train Dataset: {len(train_dataset)} samples\")\n",
    "print(f\"‚úÖ Final Test Dataset: {len(test_dataset)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Rekha\\AppData\\Local\\Temp\\ipykernel_21284\\682870947.py:36: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
      "Epoch 1/15:   0%|          | 0/17 [00:00<?, ?it/s]C:\\Users\\Rekha\\AppData\\Local\\Temp\\ipykernel_21284\\682870947.py:54: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 - Train Loss: 7.1983, Train Accuracy: 4.47%, Val Loss: 8.0408, Validation Accuracy: 2.91%\n",
      "‚úÖ Best model saved with validation accuracy: 2.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 - Train Loss: 5.5827, Train Accuracy: 4.08%, Val Loss: 8.5043, Validation Accuracy: 4.07%\n",
      "‚úÖ Best model saved with validation accuracy: 4.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 - Train Loss: 4.8329, Train Accuracy: 8.35%, Val Loss: 8.4485, Validation Accuracy: 3.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 - Train Loss: 4.3993, Train Accuracy: 12.82%, Val Loss: 8.3071, Validation Accuracy: 4.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 - Train Loss: 3.9167, Train Accuracy: 20.00%, Val Loss: 8.2803, Validation Accuracy: 7.56%\n",
      "‚úÖ Best model saved with validation accuracy: 7.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 - Train Loss: 3.4109, Train Accuracy: 26.80%, Val Loss: 8.2995, Validation Accuracy: 7.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 - Train Loss: 3.3403, Train Accuracy: 33.01%, Val Loss: 8.3859, Validation Accuracy: 8.14%\n",
      "‚úÖ Best model saved with validation accuracy: 8.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 - Train Loss: 3.1262, Train Accuracy: 38.83%, Val Loss: 8.3817, Validation Accuracy: 8.72%\n",
      "‚úÖ Best model saved with validation accuracy: 8.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 - Train Loss: 2.9863, Train Accuracy: 44.85%, Val Loss: 8.4610, Validation Accuracy: 8.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 - Train Loss: 2.8181, Train Accuracy: 48.74%, Val Loss: 8.4459, Validation Accuracy: 9.88%\n",
      "‚úÖ Best model saved with validation accuracy: 9.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 - Train Loss: 2.5458, Train Accuracy: 55.15%, Val Loss: 8.4859, Validation Accuracy: 8.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 - Train Loss: 2.5986, Train Accuracy: 57.86%, Val Loss: 8.5429, Validation Accuracy: 9.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 - Train Loss: 2.4883, Train Accuracy: 61.94%, Val Loss: 8.5670, Validation Accuracy: 10.47%\n",
      "‚úÖ Best model saved with validation accuracy: 10.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 - Train Loss: 2.3429, Train Accuracy: 66.21%, Val Loss: 8.5580, Validation Accuracy: 8.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 - Train Loss: 2.3901, Train Accuracy: 63.30%, Val Loss: 8.6190, Validation Accuracy: 7.56%\n",
      "üéâ Training complete!\n"
     ]
    }
   ],
   "source": [
    "#Fine-tuning\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "num_classes = len(label_to_index)  \n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "# Initialize new FC layer\n",
    "nn.init.xavier_uniform_(model.fc.weight)\n",
    "model.fc.bias.data.fill_(0.01)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "\n",
    "# Train the model\n",
    "epochs = 15  \n",
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\", leave=False):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    # Training loss and accuracy\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    # Validation accuracy & loss\n",
    "    val_loss /= len(test_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Learning rate scheduler step\n",
    "    scheduler.step()\n",
    "\n",
    "    # Save best model\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(f\"‚úÖ Best model saved with validation accuracy: {best_accuracy:.2f}%\")\n",
    "\n",
    "print(\"üéâ Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Extracted Text:\n",
      " Cred , Weep wie cote.\n",
      "otet\n",
      "2 go te you fr Sate t a\n",
      "\n",
      "Lerd. every thing. you bore Gives wie ¬© ares\n",
      "You law wrode my tite Secuve\n",
      "\n",
      "Hy heact glad Jey en my fevaue\n",
      "My bedy) algo wit be Secnve I\n",
      "\n",
      "You wrt qi‚Äú‚Äô me. endless, Pleasu ves ak\n",
      "\n",
      "Youle an Lion d \"Bowe port of P√©al we\n",
      "‚úÖ Extracted text saved to extracted_text.txt\n"
     ]
    }
   ],
   "source": [
    "#Inference model\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Set Tesseract-OCR Path\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "image_path = \"D:/Projects/Final_project/Dataset/data/test/eng_NA_128.jpg\"\n",
    "\n",
    "if not os.path.exists(image_path):\n",
    "    raise FileNotFoundError(f\"Error: Image file not found at {image_path}\")\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "_, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "kernel = np.ones((1, 1), np.uint8)\n",
    "binary = cv2.erode(binary, kernel, iterations=1)\n",
    "binary = cv2.dilate(binary, kernel, iterations=1)\n",
    "\n",
    "edges = cv2.Canny(binary, 50, 150)\n",
    "binary = cv2.bitwise_or(binary, edges)\n",
    "\n",
    "processed_image_path = \"processed_image.png\"\n",
    "cv2.imwrite(processed_image_path, binary)\n",
    "\n",
    "if not os.path.exists(processed_image_path):\n",
    "    raise FileNotFoundError(\"Processed image was not saved successfully!\")\n",
    "\n",
    "# ‚úÖ TRY OCR WITHOUT CUSTOM CONFIG FIRST\n",
    "try:\n",
    "    text = pytesseract.image_to_string(Image.open(processed_image_path), lang=\"eng\")\n",
    "\n",
    "    # DEBUG: Check if OCR output is empty\n",
    "    if not text.strip():\n",
    "        print(\"Warning: OCR returned empty text. Check the processed image.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"OCR Error:\", e)\n",
    "    text = \"\"  \n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.replace(\"|\", \"I\")  \n",
    "    text = text.replace(\"  \", \" \")  \n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "cleaned_text = clean_text(text)\n",
    "\n",
    "print(\"\\nüîç Extracted Text:\\n\", cleaned_text)\n",
    "\n",
    "# Save Extracted Text to a File\n",
    "output_text_path = \"extracted_text.txt\"\n",
    "with open(output_text_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(cleaned_text)\n",
    "\n",
    "print(f\"‚úÖ Extracted text saved to {output_text_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
